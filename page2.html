<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Social Media's Role</title>
    <link rel="stylesheet" href="style_sheet2.css"> <!-- linking to secondary css sheet -->
    <!-- validates fully as of Nov. 21, 2023, Dec. 5, and Dec 19-->
</head>
<body>
    <div class="pageheader">
        <div id="hTitle">
            <h2>Social Media, Cults, and Online Extremism</h2>
        </div>
    </div>
    <!-- image -->
    <div class="imgs"> <img src="images/socialmedialogos.jpg" alt="Youtube, Discord, Twitter, Facebook, Instagram logos built by legos on white background" style="width:50%"> </div>
    <!-- inserting research from PM2 basically, following a simple layout, 
        added classes to then be used in our css sheet -->    
    <div class="text">
    <div class="postTitles"> <h3>Social Media's Role in Promoting Cults</h3> </div>
        <p>“Belief in seances and tarot cards, for example, seems to spread via the mass media with 
            little mediation by social networks.” With the occult cults, social media facilitates 
            information and promotes how anyone can practice the occult. “Algorithms are mainly 
            designed to amplify information that sustains engagement, meaning they keep people 
            clicking on content and returning to the platforms.” <b>Social media algorithms</b> are 
            designed for people to continue engaging in popular content. They play a significant 
            role in determining which content gets pushed to users' feeds. Social media provides an 
            easy, cheap, and accessible platform for cults to rise and thrive and then communicate 
            with potential recruits or easy targets.
        </p>
        <p>However, with religious cults, there is a need for <b>interpersonal bonds</b> between those 
            being recruited and members of the organizations– it is essential to grow their groups. 
            Algorithms can unintentionally create <b>echo chambers</b> by showing users content that aligns 
            with their existing beliefs and opinions. This can reinforce extremist views because 
            users are rarely exposed to different perspectives. So while social media doesn't 
            intentionally try to push information on cults, the people in these cults can reach a 
            larger audience of lonely people who just want to belong to something. Cults and 
            extremist groups also often use provocative or trendy content to gain attention and 
            followers. This leads this content to then go viral (much more easily due to its 
            trendiness or outright shock factor), so algorithms may then prioritize the content 
            being pushed by cults.
        </p>
        <p>Social media algorithms encourage polarized thinking because they prioritize content 
            that tries to provoke strong reactions (meaning more social engagement). The algorithms 
            attempt to keep users using their platforms (like TikTok, Instagram, Facebook, ...) for 
            longer periods of time, and the easiest way for social media to do this is by 
            <b>personalizing</b> their algorithms to each user by showing them content that aligns with 
            their beliefs or is so provoking that they unintentionally interact making that content 
            more popular. But because, more often than not, users like to interact with posts that 
            target their pre-existing thoughts they begin to create echo chambers and communicate 
            with other like-minded individuals. Social media makes it easy for these people to 
            create groups (including cults) where they continue reinforcing one another's ideas. 
            These echo chambers make it so that users won't challenge their thinking and contribute 
            to a <b>social division caused by polarized thinking.</b> Social media's algorithms and 
            influence in creating echo chambers is very apparent within the 2016 and 2020 elections 
            as well as when COVID-19 information was coming out-- causing a lot of misinformation.
        </p>
        <p>Religious cults usually come from being a group within a much larger religion, with 
            leaders then steadily changing aspects and implementing their beliefs and personal 
            ideologies to their followers. Eventually, the leader's influence alongside <b>isolation</b> 
            causes the group to become a cult. So a big part that impacts how big a cult forms is 
            how beneficial the group seems at first. To the public, this group must initially be 
            doing some sort of good, like establishing social/community outreach programs for 
            people to feel like they’re doing good. Using <b>positive, welcoming language </b> and 
            second-person pronouns is very effective in getting people to be more willing to listen 
            to you, only after getting entrapped in a cult is it more likely you’ll be faced with 
            language that is more violent or even us vs them language and ideas. <b>Necessity modals</b> 
            (like must, have to, have got to) and <b>othering</b> (saying things such as “they won’t 
            understand us”) are also very important in the formation of non-religious cults.
        </p>
        <p>With online cults like QAnon, they manage to get a lot of traction via Twitter, Facebook, 
            and YouTube video recommendations (the more clicks or outrageous a video title 
            (<b>clickbait</b>) the more likely to click on it and learn all about it). They established a 
            mobile application and created Facebook groups with tens of thousands of members. While 
            many considered this group to be a conspiracy theory, the way they act (including having 
            many people of all ages give up their family and friends to remain in the online 
            community and committed to their beliefs) is more closely aligned to that of a cult with 
            its homebase on the internet. The people who seem to be more likely to join QAnon are 
            middle-class Americans who lost out in the 2008 financial crisis or are unemployed, 
            meaning that they feel <b>powerless</b> and are looking to find meaning somewhere when they 
            encounter this group. </p>
        <p>The most engaging content triggers <b>emotional reactions</b>, which is different for each app 
            or website. For example, what tends to go viral on Twitter is content that prompts 
            outrage and anger or on the opposite— content that aims to bring people together. It’s 
            a manner of content for like-minded people or those trying to pick fights over the web. 
            Twitter, while not being as socially big for people as Facebook or TikTok, does have a 
            rather big influence on politics because the discourse it causes is mostly aimed toward 
            the larger amount of politicians on the app. <b>Narcissists</b> are also more likely to be on 
            Twitter because it feeds into their sense of superiority— they’re also more likely to 
            be addicted to social media in general. TikTok’s algorithms are quite guarded though so 
            the exact specifics are not open for the public to dissect. This secrecy contributes to 
            the platform's ability to influence user behavior in ways that are not fully understood 
            by the public, potentially amplifying certain types of content over others without 
            clear transparency. </p>
        <!-- <h4>Resources: </h4>
        <ul>
            <li> <a href="http://www.jstor.org/stable/2778383"> Stark, Rodney, and William Sims Bainbridge. 
                “Networks of Faith: Interpersonal Bonds and Recruitment to Cults and Sects.” American Journal 
                of Sociology, vol. 85, no. 6, 1980, pp. 1376–95. JSTOR, http://www.jstor.org/stable/2778383. 
                Accessed 3 Nov. 2023.</a></li>
            <li> <a href="https://link.gale.com/apps/doc/A761782113/ITOF?u=mlin_m_wellcol&sid=bookmark-ITOF&xid=a8241688">"Social media algorithms warp how people learn from each other." Business Mirror 
                [Makati City, Philippines], 23 Aug. 2023, p. NA. Gale General OneFile, 
                link.gale.com/apps/doc/A761782113/ITOF?u=mlin_m_wellcol&sid=bookmark-ITOF&xid=a8241688. 
                Accessed 3 Nov. 2023. </a></li>
            <li>
                <a href="https://search.ebscohost.com/login.aspx?direct=true&AuthType=ip,sso&db=ufh&AN=155184362&site=eds-live&scope=site&custid=s8895369">
                    Rhodes, Samuel C. “Filter Bubbles, Echo Chambers, and Fake News: How Social Media Conditions 
                    Individuals to Be Less Critical of Political Misinformation.” Political Communication, 
                    vol. 39, no. 1, Jan. 2022, pp. 1–22. EBSCOhost, https://doi.org/10.1080/10584609.2021.1910887.</a></li>
        </ul> -->
        <a href="home.html" class="returnButton">« Back to Homepage</a>
    </div>
</body>
</html>